{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "import string\n",
    "import multiprocessing\n",
    "from tqdm import tqdm, trange\n",
    "import operator\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#files\n",
    "trainDir = \"aclimdb/train/\"\n",
    "testDir = \"aclimdb/test/\"\n",
    "contenttrain = []\n",
    "labeltrain = []\n",
    "contenttest = []\n",
    "labeltest = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#extracting data\n",
    "for i in listdir(trainDir+'pos'):\n",
    "    contenttrain.append(open(trainDir+'pos/'+i,'r').read())\n",
    "    labeltrain.append('1')\n",
    "for i in listdir(trainDir+'neg'):\n",
    "    contenttrain.append(open(trainDir+'neg/'+i,'r').read())\n",
    "    labeltrain.append('0')\n",
    "for i in listdir(testDir+'pos'):\n",
    "    contenttest.append(open(testDir+'pos/'+i,'r').read())\n",
    "    labeltest.append('1')\n",
    "for i in listdir(testDir+'neg'):\n",
    "    contenttest.append(open(testDir+'neg/'+i,'r').read())\n",
    "    labeltest.append('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#shuffling\n",
    "trainData = pd.DataFrame({\"content\":contenttrain,\"label\":labeltrain})\n",
    "trainData = trainData.iloc[np.random.permutation(len(trainData))]\n",
    "testData = pd.DataFrame({\"content\":contenttest,\"label\":labeltest})\n",
    "testData = testData.iloc[np.random.permutation(len(testData))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pickle\n",
    "testData.to_pickle(\"model/test.pkl\")\n",
    "trainData.to_pickle(\"model/train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def createSententencesArray(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creting tokens\n",
    "def preprocessSentence(sent):\n",
    "    sent =  sent[0]\n",
    "    tokens = ''.join(('' if i.isdigit() else i) for i in (sent) if (i not in string.punctuation) ).lower()\n",
    "    return nltk.word_tokenize(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating tokens for each sentence\n",
    "train_sentences = list(np.array(trainData[['content']]))\n",
    "train_sentences_all = []\n",
    "test_sentences_all = []\n",
    "for i in train_sentences:\n",
    "    train_sentences_all.append(preprocessSentence(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#word to vec\n",
    "cores = multiprocessing.cpu_count()\n",
    "model_train = Word2Vec(train_sentences_all,size=200, window=5, min_count=1, workers=cores, iter=1)\n",
    "model_train.save('model/model_train.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#padding\n",
    "max_index, max_value = max(enumerate(i for i in train_sentences_all), key=operator.itemgetter(1))\n",
    "for i in train_sentences_all:\n",
    "    i+=list('0'*(len(max_value)-len(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sentences_all[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
